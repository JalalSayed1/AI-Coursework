{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "anticipated-consumer",
      "metadata": {
        "id": "anticipated-consumer"
      },
      "source": [
        "In this assignment, we are going to implement see if we can optimally select a subset of training instances for supervised learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "higher-nebraska",
      "metadata": {
        "id": "higher-nebraska"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-09 18:31:14.570735: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-09 18:31:14.573061: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-09 18:31:14.608211: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-09 18:31:14.608249: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-09 18:31:14.608267: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-09 18:31:14.614760: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-01-09 18:31:14.615445: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-01-09 18:31:15.396126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daily-internship",
      "metadata": {
        "id": "daily-internship"
      },
      "source": [
        "We are going to work with the MNIST dataset, a popular dataset for hand-written digit recognition. Here we load the datatset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "palestinian-texas",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "palestinian-texas",
        "outputId": "2e6494ee-e47d-4968-e8b5-01374df7d5e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "Loaded 60000 train samples\n",
            "Loaded 10000 test samples\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "Loaded 60000 train samples\n",
            "Loaded 10000 test samples\n",
            "Num of data points per class in train set: [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1) # -1 means the last axis\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"Loaded {} train samples\".format(x_train.shape[0]))\n",
        "print(\"Loaded {} test samples\".format(x_test.shape[0]))\n",
        "\n",
        "#! scale down the training set to 10_000 samples\n",
        "import random\n",
        "random.seed(42)\n",
        "train_size = 10_200\n",
        "test_size = 200\n",
        "# make x_train have roughly same number of samples for each class:\n",
        "# x_train = np.concatenate([x_train[y_train == i][:train_size // 10] for i in range(10)])\n",
        "# y_train = np.concatenate([y_train[y_train == i][:train_size // 10] for i in range(10)])\n",
        "# # make x_test have roughly same number of samples for each class:\n",
        "# x_test = np.concatenate([x_test[y_test == i][:test_size // 10] for i in range(10)])\n",
        "# y_test = np.concatenate([y_test[y_test == i][:test_size // 10] for i in range(10)])\n",
        "\n",
        "# x_train = x_train[:train_size]\n",
        "# y_train = y_train[:train_size]\n",
        "# get test sets from x_train and y_train:\n",
        "# random_indices = np.random.choice(x_train.shape[0], size=test_size, replace=False)\n",
        "# x_test = x_train[random_indices]\n",
        "# y_test = y_train[random_indices]\n",
        "# delete the test sets from x_train and y_train:\n",
        "# x_train = np.delete(x_train, random_indices, axis=0)\n",
        "# y_train = np.delete(y_train, random_indices)\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"Loaded {} train samples\".format(x_train.shape[0]))\n",
        "print(\"Loaded {} test samples\".format(x_test.shape[0]))\n",
        "print(f\"Num of data points per class in train set: {np.unique(y_train, return_counts=True)[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "95504f5b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
          ]
        }
      ],
      "source": [
        "# count how many data points are in each class\n",
        "res = np.unique(y_train, return_counts=True)\n",
        "print({k:v for k,v in zip(res[0], res[1])})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "empty-desert",
      "metadata": {
        "id": "empty-desert"
      },
      "source": [
        "Now corrupt the labels with common types of mistakes. The variable 'noise_probability' controls the amount of errors introduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "champion-technician",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "champion-technician",
        "outputId": "ab792401-d617-4afb-d634-5df238e0ee19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Corruptions: {'5->6': 2666, '0->2': 2917, '4->7': 2888, '1->4': 3385, '9->0': 2997, '2->3': 2969, '3->5': 3027, '7->1': 3204, '8->9': 2911, '6->8': 2960}\n",
            "Number of corruptions: 29934\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "noise_probability = 0.5\n",
        "SEED = 314159\n",
        "\n",
        "random.seed(SEED)\n",
        "\n",
        "def index(array, item):\n",
        "    for i in range(len(array)):\n",
        "        if item == array[i]:\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "def corrupt_label(y, y_index, err):\n",
        "    n = len(err)\n",
        "    # select an element at random (index != found)\n",
        "    if (y_index == n-1):\n",
        "        noisy_label = err[0]\n",
        "    else:\n",
        "        noisy_label = err[(y_index + 1)%n]\n",
        "    return noisy_label\n",
        "\n",
        "# We corrupt the MNIST data with some common mistakes, such as 3-->8, 8-->3, 1-->{4, 7}, 5-->6 etc.\n",
        "def corrupt_labels(y_train, noise_probability):\n",
        "    num_samples = y_train.shape[0]\n",
        "    err_es_1 = np.array([0, 2, 3, 5, 6, 8, 9])\n",
        "    err_es_2 = np.array([1, 4, 7])\n",
        "\n",
        "    corruptions = {}\n",
        "    corrupted_indexes = {}\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        p = random.random()\n",
        "\n",
        "        if p < noise_probability:\n",
        "            y = y_train[i]\n",
        "\n",
        "            y_index = index(err_es_1, y)\n",
        "            if y_index >= 0:\n",
        "                y_noisy = corrupt_label(y, y_index, err_es_1)\n",
        "            else:\n",
        "                y_index = index(err_es_2, y)\n",
        "                y_noisy = corrupt_label(y, y_index, err_es_2)\n",
        "\n",
        "            key = str(y_train[i]) + '->' + str(y_noisy)\n",
        "            corrupted_indexes[i] = i\n",
        "\n",
        "            if key in corruptions:\n",
        "                corruptions[key] += 1\n",
        "            else:\n",
        "                corruptions[key] = 0\n",
        "\n",
        "            y_train[i] = y_noisy\n",
        "\n",
        "    return corruptions, corrupted_indexes\n",
        "\n",
        "corruptions, corrupted_indexes = corrupt_labels(y_train, noise_probability)\n",
        "print (\"Corruptions: \" + str(corruptions))\n",
        "print (\"Number of corruptions: {}\".format(len(list(corrupted_indexes.keys()))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3fd83ff4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of pruned indexes: 29934\n"
          ]
        }
      ],
      "source": [
        "print(f\"Length of pruned indexes: {len(corrupted_indexes)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4ee48cb6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 6003, 1: 6561, 2: 5906, 3: 6073, 4: 6339, 5: 5782, 6: 5624, 7: 5949, 8: 5900, 9: 5863}\n"
          ]
        }
      ],
      "source": [
        "# count how many data points are in each class after corruption\n",
        "res = np.unique(y_train, return_counts=True)\n",
        "print({k:v for k,v in zip(res[0], res[1])})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "quality-gauge",
      "metadata": {
        "id": "quality-gauge"
      },
      "outputs": [],
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train_onehot = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test_onehot = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fifth-celebrity",
      "metadata": {
        "id": "fifth-celebrity"
      },
      "source": [
        "Supervised (parametric) training with the (noisy) labeled examples. Note that this model is trained on the entire dataset (the value of the parameter pruned_indexes is null here, which means that we leave out no points), which is noisy (20% of the labels are corrupted). Now the question is: is this the best model that we can train or can we do better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "extreme-ethernet",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extreme-ethernet",
        "outputId": "cb7c5e23-7242-4c71-c830-88dabc51ca3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 5408)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                54090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54410 (212.54 KB)\n",
            "Trainable params: 54410 (212.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "epochs = 3\n",
        "validation_split=0.1\n",
        "\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "def prune_points(x_train, y_train, pruned_indexes):\n",
        "    num_samples = x_train.shape[0]\n",
        "    x_train_pruned = []\n",
        "    y_train_pruned = []\n",
        "    for i in range(num_samples):\n",
        "        if not i in pruned_indexes:\n",
        "            x_train_pruned.append(x_train[i])\n",
        "            y_train_pruned.append(y_train[i])\n",
        "\n",
        "    return np.array(x_train_pruned), np.array(y_train_pruned)\n",
        "\n",
        "def trainAndEvaluateModel(x_train, y_train, x_test, y_test, model, pruned_indexes):\n",
        "\n",
        "    if not pruned_indexes == None:\n",
        "        x_train_pruned, y_train_pruned = prune_points(x_train, y_train, pruned_indexes)\n",
        "    else:\n",
        "        x_train_pruned = x_train\n",
        "        y_train_pruned = y_train\n",
        "\n",
        "    model.fit(x_train_pruned, y_train_pruned, batch_size=batch_size, epochs=epochs)\n",
        "    loss, accuracy = model.evaluate(x_test, y_test)\n",
        "    keras.backend.clear_session() # remove previous training weights\n",
        "    \n",
        "    return loss, accuracy\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "indie-waterproof",
      "metadata": {
        "id": "indie-waterproof"
      },
      "source": [
        "And we call the following function to train a model on the entire dataset and evaluate it on the test set. The accuracy on the test set is quite good, but can we do better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "embedded-staff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "embedded-staff",
        "outputId": "707551e0-dc21-4016-8ba9-3b9e05de1069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "469/469 [==============================] - 8s 16ms/step - loss: 1.2018 - accuracy: 0.4410\n",
            "Epoch 2/3\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.9879 - accuracy: 0.4766\n",
            "Epoch 3/3\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 0.9485 - accuracy: 0.4866\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.9076 - accuracy: 0.4645\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.9075835943222046, 0.4645000100135803)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainAndEvaluateModel(x_train, y_train_onehot, x_test, y_test_onehot, model, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-lithuania",
      "metadata": {
        "id": "structured-lithuania"
      },
      "source": [
        "You need to implement a subset selection function that when called will return a subset of instances which will be used to train the model. This setup ensures that you also pass in another dictionary which contains the indexes of the instances that you would not want to use while training the model, i.e., it should contain a list of indexes that you would decide to **leave out** for training.\n",
        "\n",
        "Here's the code and a sample implementation that returns a randomly chosen set of instances that you are to be left out. Since we chose 70% probability of label corruption (check the **noise_probability** parameter), we also select a subset where we leave out the same proportion of points. This is a baseline implementation and obviously you should aim to achieve better results than this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "unique-operator",
      "metadata": {
        "id": "unique-operator"
      },
      "outputs": [],
      "source": [
        "# Here 'x_train', 'y_train' and model' are an unused parameters. But you may get better results by leveraging these.\n",
        "def baseLinePrunedSubsetMethod(x_train, y_train, model):\n",
        "    pruned_indexes = {}\n",
        "    num_samples = x_train.shape[0]\n",
        "    for i in range(num_samples):\n",
        "        p = random.random()\n",
        "\n",
        "        if p < noise_probability: # this is the global variable (only useful for this naive approach)\n",
        "            pruned_indexes[i] = i\n",
        "    return pruned_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stunning-steel",
      "metadata": {
        "id": "stunning-steel"
      },
      "source": [
        "Let's see how this naive baseline works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "formed-refrigerator",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "formed-refrigerator",
        "outputId": "b37fa32f-1af8-417c-8a33-1f53d42157ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "237/237 [==============================] - 4s 15ms/step - loss: 0.9252 - accuracy: 0.4941\n",
            "Epoch 2/3\n",
            "237/237 [==============================] - 4s 15ms/step - loss: 0.9137 - accuracy: 0.5014\n",
            "Epoch 3/3\n",
            "237/237 [==============================] - 4s 15ms/step - loss: 0.8991 - accuracy: 0.5031\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8986 - accuracy: 0.4681\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.8986325263977051, 0.46810001134872437)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pruned_indexes = baseLinePrunedSubsetMethod(x_train, y_train, model)\n",
        "trainAndEvaluateModel(x_train, y_train_onehot, x_test, y_test_onehot, model, pruned_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "backed-cache",
      "metadata": {
        "id": "backed-cache"
      },
      "source": [
        "Let's now see if we had known what points were actually corrupted (more of a hypothetical unrealistic situation), does leaving out those points actually improve the model's effectiveness. It turns out that it does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "amino-orientation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amino-orientation",
        "outputId": "ed71db95-e2da-4d84-ddb0-8b815f73d1ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.2412 - accuracy: 0.9247\n",
            "Epoch 2/3\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.1395 - accuracy: 0.9604\n",
            "Epoch 3/3\n",
            "235/235 [==============================] - 3s 15ms/step - loss: 0.1214 - accuracy: 0.9634\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9731\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.09582974761724472, 0.9731000065803528)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainAndEvaluateModel(x_train, y_train_onehot, x_test, y_test_onehot, model, corrupted_indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bright-constitutional",
      "metadata": {
        "id": "bright-constitutional"
      },
      "source": [
        "Your task is to implement your own version of (say of name **myPrunedSubsetMethod** (which should take as arguments x_train, y_train, and the model). The function should return a dictionary of indexes that are to be left out. Plug your function in and evaluate the results. Write a thorough report on the methodology and analyse the results.\n",
        "\n",
        "Some hints:\n",
        "You can approach this as a discrete state space optimisation problem, where firstly you can define a \"selection batch size\" (this is not the same as training batch size), which decides which batch of instances you're going to leave out. For instance, if you are in a state where the training set is $X$, you may select (by some heuristics) which points you're gonna leave out (let that set be $\\delta \\subset X$) so that a child state becomes $X' = X - \\delta$. Similarly, if you choose a different $\\delta$ you get a different child state. You then need to train and evaluate (call the function *trainAndEvaluateModel*) to see if that child state led to an improvement or not.\n",
        "\n",
        "You are free to use any algorithm, e.g., simulated annealing, A* search, genetic algorithm etc. to implement this discrete state space optimisation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f1269e4",
      "metadata": {},
      "source": [
        "# Using Genetic Algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f7834ad5",
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "INPUT_SIZE = x_train.shape[0]\n",
        "\n",
        "#' Define GA parameters\n",
        "POPULATION_SIZE = 1 # number of individuals in population\n",
        "SELECTION_SIZE = ceil(0.5*POPULATION_SIZE) # number of individuals to select for next generation\n",
        "BATTLE_PARTICIPANTS = 4 # number of individuals to participate in a tournament\n",
        "MUTATION_RATE = 0.01 # probability of mutating each individual\n",
        "CROSSOVER_RATE = 0.3 # probability of crossing over two individuals\n",
        "CROSSOVER_POINTS = 2 # number of crossover points\n",
        "GENERATIONS = 1 # number of generations\n",
        "ELITE_NUM = 2 # number of elite individuals to keep from one generation to the next"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da72613c",
      "metadata": {},
      "source": [
        "## Initialise Population:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2d2d0871",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_population(population_size, input_size, y_train, bias_strength=0.5):\n",
        "    # 0 means prune the point, 1 means keep the point:\n",
        "    population = []\n",
        "    \n",
        "    POPULATION_SIZE = population_size\n",
        "    INPUT_SIZE = input_size\n",
        "    \n",
        "    #! random\n",
        "    # if len(population) < POPULATION_SIZE:\n",
        "        # print(f\"making population of random\")\n",
        "    # while len(population) < POPULATION_SIZE:\n",
        "    #     individual = np.random.choice([0, 1], size=INPUT_SIZE)\n",
        "    #     population.append(individual)\n",
        "\n",
        "    # Calculate inverse frequencies for prioritization\n",
        "    classes, freq = np.unique(y_train, return_counts=True)\n",
        "    class_frequencies = {k:v for k,v in zip(classes, freq)}\n",
        "    max_freq = max(class_frequencies.values())\n",
        "    prioritization_scores = {digit_class: max_freq / freq for digit_class, freq in class_frequencies.items()}\n",
        "\n",
        "    for _ in range(population_size):\n",
        "        individual = np.zeros(input_size, dtype=int)\n",
        "        for i in range(input_size):\n",
        "            # random.seed(SEED)\n",
        "            class_label = y_train[i]\n",
        "            # Bias towards selecting indices of less frequent classes\n",
        "            if random.random() < (prioritization_scores[class_label] * bias_strength / max_freq):\n",
        "                individual[i] = 1\n",
        "        population.append(individual)\n",
        "\n",
        "\n",
        "    # convert to tuple for hashability:\n",
        "    population = [tuple(individual) for individual in population]\n",
        "\n",
        "    return population\n",
        "\n",
        "# population = create_population(POPULATION_SIZE, INPUT_SIZE)\n",
        "# print(f\"Sample individual: {population[0]}\")\n",
        "# print(f\"We created {len(population)} individuals in the population, each with {len(population[0])} genes\")\n",
        "\n",
        "#! Example usage:\n",
        "# population_size = 1\n",
        "# accuracy = 0.0\n",
        "# iterations = 0\n",
        "# population = []\n",
        "# # almost max is 6000\n",
        "# bias = 5800\n",
        "\n",
        "# random.seed(42)\n",
        "# res_acc = []\n",
        "# res_bias = []\n",
        "\n",
        "# population = create_population(population_size, INPUT_SIZE, y_train, bias_strength=bias)\n",
        "# pruned_indexes = {i:i for i,elt in enumerate(population[0]) if elt == 1}\n",
        "# loss, accuracy = trainAndEvaluateModel(x_train, y_train_onehot, x_test, y_test_onehot, model, pruned_indexes)\n",
        "# print(f\"Length of pruned indexes: {len(pruned_indexes)}\")\n",
        "# print(f\"bias: {bias}, accuracy: {accuracy}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4581588b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(res_bias, res_acc)\n",
        "# plt.xscale('log')\n",
        "# plt.xticks(res_bias, res_bias)\n",
        "# # save svg\n",
        "# plt.savefig(\"bias_vs_acc.svg\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "999d7d90",
      "metadata": {},
      "source": [
        "## Run Genetic Algorithm:\n",
        "- Evaluate fitness of each individual\n",
        "- Select parents\n",
        "- Crossover\n",
        "- Mutation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ba7899e7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.9118 - accuracy: 0.5566\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.8769 - accuracy: 0.6264\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7551 - accuracy: 0.6631\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.9270 - accuracy: 0.5710\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7716 - accuracy: 0.6482\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7336 - accuracy: 0.6683\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7031 - accuracy: 0.6674\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.1537 - accuracy: 0.5251\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.7108 - accuracy: 0.6743\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6824 - accuracy: 0.6844\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6715 - accuracy: 0.6804\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.2349 - accuracy: 0.5389\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.6800\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6730 - accuracy: 0.6902\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.6543 - accuracy: 0.7008\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.3019 - accuracy: 0.5152\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6628 - accuracy: 0.6846\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.6573 - accuracy: 0.6946\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.6243 - accuracy: 0.7169\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3680 - accuracy: 0.4842\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.7127 - accuracy: 0.6746\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6957 - accuracy: 0.6755\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.6696 - accuracy: 0.6833\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3201 - accuracy: 0.4967\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6989 - accuracy: 0.6775\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.6626 - accuracy: 0.6889\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6453 - accuracy: 0.7015\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.4003 - accuracy: 0.5010\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6967 - accuracy: 0.6656\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.6723 - accuracy: 0.6696\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6590 - accuracy: 0.6850\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4344 - accuracy: 0.4633\n",
            "Epoch 1/3\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.6929 - accuracy: 0.6884\n",
            "Epoch 2/3\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.6620 - accuracy: 0.7046\n",
            "Epoch 3/3\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.6557 - accuracy: 0.6954\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.4142 - accuracy: 0.5130\n",
            "Epoch 1/3\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.6603 - accuracy: 0.6980\n",
            "Epoch 2/3\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.6492 - accuracy: 0.6989\n",
            "Epoch 3/3\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.6339 - accuracy: 0.7036\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4410 - accuracy: 0.4749\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 0: 0.5709999799728394\n",
            "Best solution so far: 0.57 at generation 0\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.6637 - accuracy: 0.6795\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.6459 - accuracy: 0.6861\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.6292 - accuracy: 0.6905\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.3738 - accuracy: 0.4846\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.6558 - accuracy: 0.6901\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.6429 - accuracy: 0.6919\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.6204 - accuracy: 0.7046\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.4205 - accuracy: 0.5273\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.6099 - accuracy: 0.7033\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 20ms/step - loss: 0.5884 - accuracy: 0.7284\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.5878 - accuracy: 0.7204\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4702 - accuracy: 0.5198\n",
            "Epoch 1/3\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.6702 - accuracy: 0.6835\n",
            "Epoch 2/3\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.6418 - accuracy: 0.6968\n",
            "Epoch 3/3\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.6225 - accuracy: 0.7031\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5177 - accuracy: 0.4781\n",
            "Epoch 1/3\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.6471 - accuracy: 0.7028\n",
            "Epoch 2/3\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6353 - accuracy: 0.7019\n",
            "Epoch 3/3\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.6121 - accuracy: 0.7236\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.4931 - accuracy: 0.4854\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.9846 - accuracy: 0.5628\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.8266 - accuracy: 0.5930\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.7915 - accuracy: 0.6035\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8299 - accuracy: 0.5594\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 18ms/step - loss: 0.8455 - accuracy: 0.5566\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.8169 - accuracy: 0.5733\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 16ms/step - loss: 0.8022 - accuracy: 0.5850\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8756 - accuracy: 0.4928\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 0.8355 - accuracy: 0.5599\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 0.8131 - accuracy: 0.5802\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.8029 - accuracy: 0.5812\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8494 - accuracy: 0.4983\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 0.8345 - accuracy: 0.5560\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.8045 - accuracy: 0.5750\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.7838 - accuracy: 0.5832\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8490 - accuracy: 0.5393\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.8181 - accuracy: 0.5694\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.7966 - accuracy: 0.5856\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.7919 - accuracy: 0.5854\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8609 - accuracy: 0.5392\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 1: 0.5594000220298767\n",
            "Best solution so far: 0.57 at generation 1\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.7899 - accuracy: 0.5885\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.7544 - accuracy: 0.6047\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.7352 - accuracy: 0.6213\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8382 - accuracy: 0.5595\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.8000 - accuracy: 0.5785\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.7761 - accuracy: 0.5957\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 0.7566 - accuracy: 0.6099\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8597 - accuracy: 0.4948\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 0.7373 - accuracy: 0.6174\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 0.7327 - accuracy: 0.6225\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.7265 - accuracy: 0.6272\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8707 - accuracy: 0.5276\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.8094 - accuracy: 0.5762\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.7768 - accuracy: 0.6026\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 30ms/step - loss: 0.7624 - accuracy: 0.6022\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.8656 - accuracy: 0.5226\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.7962 - accuracy: 0.5770\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 30ms/step - loss: 0.7733 - accuracy: 0.6008\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 25ms/step - loss: 0.7543 - accuracy: 0.6140\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8844 - accuracy: 0.4920\n",
            "Epoch 1/3\n",
            "58/58 [==============================] - 1s 20ms/step - loss: 0.8127 - accuracy: 0.5591\n",
            "Epoch 2/3\n",
            "58/58 [==============================] - 1s 21ms/step - loss: 0.7857 - accuracy: 0.5841\n",
            "Epoch 3/3\n",
            "58/58 [==============================] - 1s 22ms/step - loss: 0.7737 - accuracy: 0.5869\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8578 - accuracy: 0.5067\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.8159 - accuracy: 0.5627\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 24ms/step - loss: 0.7889 - accuracy: 0.5719\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.7864 - accuracy: 0.5853\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8456 - accuracy: 0.5068\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.7855 - accuracy: 0.5828\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.7777 - accuracy: 0.5927\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.7629 - accuracy: 0.6039\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8739 - accuracy: 0.4869\n",
            "Epoch 1/3\n",
            "68/68 [==============================] - 2s 21ms/step - loss: 0.8219 - accuracy: 0.5604\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.8010 - accuracy: 0.5777\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 2s 24ms/step - loss: 0.7931 - accuracy: 0.5734\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8319 - accuracy: 0.5054\n",
            "Epoch 1/3\n",
            "61/61 [==============================] - 1s 20ms/step - loss: 0.8218 - accuracy: 0.5656\n",
            "Epoch 2/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.8013 - accuracy: 0.5750\n",
            "Epoch 3/3\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.7860 - accuracy: 0.5913\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8768 - accuracy: 0.4869\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 2: 0.559499979019165\n",
            "Best solution so far: 0.57 at generation 2\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.7845 - accuracy: 0.5871\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.7484 - accuracy: 0.6136\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.7346 - accuracy: 0.6284\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8525 - accuracy: 0.5377\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.7615 - accuracy: 0.6024\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.7326 - accuracy: 0.6172\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.7219 - accuracy: 0.6256\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8634 - accuracy: 0.5195\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.7193 - accuracy: 0.6282\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.6943 - accuracy: 0.6513\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.6877 - accuracy: 0.6489\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8643 - accuracy: 0.5419\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.6850 - accuracy: 0.6487\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.6686 - accuracy: 0.6596\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.6619 - accuracy: 0.6704\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8587 - accuracy: 0.5521\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.6488 - accuracy: 0.6677\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.6576 - accuracy: 0.6704\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.6429 - accuracy: 0.6724\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8858 - accuracy: 0.5345\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.7579 - accuracy: 0.6092\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7520 - accuracy: 0.6100\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.7344 - accuracy: 0.6239\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8535 - accuracy: 0.5018\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7464 - accuracy: 0.6219\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7333 - accuracy: 0.6290\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.7231 - accuracy: 0.6298\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8643 - accuracy: 0.5140\n",
            "Epoch 1/3\n",
            "67/67 [==============================] - 2s 22ms/step - loss: 0.7672 - accuracy: 0.6089\n",
            "Epoch 2/3\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 0.7435 - accuracy: 0.6210\n",
            "Epoch 3/3\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 0.7326 - accuracy: 0.6270\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8635 - accuracy: 0.5134\n",
            "Epoch 1/3\n",
            "68/68 [==============================] - 2s 21ms/step - loss: 0.7466 - accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.7365 - accuracy: 0.6168\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 2s 23ms/step - loss: 0.7284 - accuracy: 0.6220\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8444 - accuracy: 0.5025\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.7338 - accuracy: 0.6206\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.7227 - accuracy: 0.6337\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.7171 - accuracy: 0.6277\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8498 - accuracy: 0.5079\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 3: 0.5521000027656555\n",
            "Best solution so far: 0.57 at generation 3\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.6132 - accuracy: 0.6968\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.6079 - accuracy: 0.6972\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5935 - accuracy: 0.7112\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8527 - accuracy: 0.5434\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.5963 - accuracy: 0.7130\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.5870 - accuracy: 0.7193\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.5898 - accuracy: 0.7073\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8807 - accuracy: 0.5198\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.5752 - accuracy: 0.7154\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.5753 - accuracy: 0.7290\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.5688 - accuracy: 0.7158\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8818 - accuracy: 0.5530\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.8272 - accuracy: 0.5687\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.7868 - accuracy: 0.5954\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.7598 - accuracy: 0.6082\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8613 - accuracy: 0.5457\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.6017 - accuracy: 0.7089\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.5847 - accuracy: 0.7172\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5672 - accuracy: 0.7233\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8703 - accuracy: 0.5512\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 22ms/step - loss: 0.7168 - accuracy: 0.6429\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.6887 - accuracy: 0.6657\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.6876 - accuracy: 0.6547\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8799 - accuracy: 0.4841\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7706 - accuracy: 0.6025\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.7432 - accuracy: 0.6169\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.7291 - accuracy: 0.6295\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8427 - accuracy: 0.5522\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7158 - accuracy: 0.6385\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.7034 - accuracy: 0.6421\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.6966 - accuracy: 0.6447\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8302 - accuracy: 0.5418\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.7606 - accuracy: 0.6095\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.7332 - accuracy: 0.6230\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7285 - accuracy: 0.6286\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8580 - accuracy: 0.5263\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.7235 - accuracy: 0.6303\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.7026 - accuracy: 0.6464\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.6913 - accuracy: 0.6505\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8713 - accuracy: 0.5025\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 4: 0.5529999732971191\n",
            "Best solution so far: 0.57 at generation 4\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5753 - accuracy: 0.7266\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.5615 - accuracy: 0.7321\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.5681 - accuracy: 0.7292\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8601 - accuracy: 0.5274\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.7420 - accuracy: 0.6163\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 23ms/step - loss: 0.7187 - accuracy: 0.6396\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.7103 - accuracy: 0.6380\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8499 - accuracy: 0.5262\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.6925 - accuracy: 0.6481\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.6961 - accuracy: 0.6486\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.6805 - accuracy: 0.6547\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8629 - accuracy: 0.5403\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5916 - accuracy: 0.7168\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5694 - accuracy: 0.7237\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5610 - accuracy: 0.7288\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.5356\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.6849 - accuracy: 0.6556\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 20ms/step - loss: 0.6701 - accuracy: 0.6639\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.6623 - accuracy: 0.6719\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8713 - accuracy: 0.5201\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 20ms/step - loss: 0.7315 - accuracy: 0.6348\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 22ms/step - loss: 0.7068 - accuracy: 0.6496\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 22ms/step - loss: 0.6888 - accuracy: 0.6601\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8468 - accuracy: 0.5321\n",
            "Epoch 1/3\n",
            "77/77 [==============================] - 2s 21ms/step - loss: 0.7475 - accuracy: 0.6238\n",
            "Epoch 2/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.7407 - accuracy: 0.6217\n",
            "Epoch 3/3\n",
            "77/77 [==============================] - 2s 21ms/step - loss: 0.7198 - accuracy: 0.6319\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8713 - accuracy: 0.5036\n",
            "Epoch 1/3\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.7236 - accuracy: 0.6388\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.7117 - accuracy: 0.6392\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.7025 - accuracy: 0.6423\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8412 - accuracy: 0.5309\n",
            "Epoch 1/3\n",
            "76/76 [==============================] - 2s 23ms/step - loss: 0.7400 - accuracy: 0.6305\n",
            "Epoch 2/3\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7149 - accuracy: 0.6402\n",
            "Epoch 3/3\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.7137 - accuracy: 0.6399\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8244 - accuracy: 0.5309\n",
            "Epoch 1/3\n",
            "68/68 [==============================] - 1s 20ms/step - loss: 0.7213 - accuracy: 0.6295\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 2s 23ms/step - loss: 0.7086 - accuracy: 0.6406\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.7038 - accuracy: 0.6354\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8428 - accuracy: 0.5129\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 5: 0.5403000116348267\n",
            "Best solution so far: 0.57 at generation 5\n",
            "Epoch 1/3\n",
            "60/60 [==============================] - 2s 24ms/step - loss: 0.7156 - accuracy: 0.6304\n",
            "Epoch 2/3\n",
            "60/60 [==============================] - 1s 21ms/step - loss: 0.6913 - accuracy: 0.6474\n",
            "Epoch 3/3\n",
            "60/60 [==============================] - 1s 22ms/step - loss: 0.6757 - accuracy: 0.6597\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8564 - accuracy: 0.5166\n",
            "Epoch 1/3\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.6740 - accuracy: 0.6593\n",
            "Epoch 2/3\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.6587 - accuracy: 0.6759\n",
            "Epoch 3/3\n",
            "59/59 [==============================] - 1s 23ms/step - loss: 0.6552 - accuracy: 0.6752\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8706 - accuracy: 0.5118\n",
            "Epoch 1/3\n",
            "68/68 [==============================] - 2s 22ms/step - loss: 0.6872 - accuracy: 0.6546\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 1s 21ms/step - loss: 0.6720 - accuracy: 0.6647\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.6710 - accuracy: 0.6620\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8584 - accuracy: 0.5079\n",
            "Epoch 1/3\n",
            "76/76 [==============================] - 2s 20ms/step - loss: 0.7020 - accuracy: 0.6460\n",
            "Epoch 2/3\n",
            "76/76 [==============================] - 2s 24ms/step - loss: 0.7017 - accuracy: 0.6418\n",
            "Epoch 3/3\n",
            "76/76 [==============================] - 2s 21ms/step - loss: 0.6918 - accuracy: 0.6524\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8408 - accuracy: 0.5210\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.5659 - accuracy: 0.7321\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.5484 - accuracy: 0.7363\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5399 - accuracy: 0.7418\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8742 - accuracy: 0.5244\n",
            "Epoch 1/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.7014 - accuracy: 0.6576\n",
            "Epoch 2/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.6868 - accuracy: 0.6664\n",
            "Epoch 3/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.6728 - accuracy: 0.6687\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8408 - accuracy: 0.5365\n",
            "Epoch 1/3\n",
            "68/68 [==============================] - 2s 21ms/step - loss: 0.7581 - accuracy: 0.6136\n",
            "Epoch 2/3\n",
            "68/68 [==============================] - 1s 22ms/step - loss: 0.7400 - accuracy: 0.6238\n",
            "Epoch 3/3\n",
            "68/68 [==============================] - 2s 23ms/step - loss: 0.7230 - accuracy: 0.6316\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8482 - accuracy: 0.5305\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.7448 - accuracy: 0.6128\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.7287 - accuracy: 0.6269\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.7126 - accuracy: 0.6392\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8710 - accuracy: 0.4831\n",
            "Epoch 1/3\n",
            "77/77 [==============================] - 2s 20ms/step - loss: 0.7468 - accuracy: 0.6142\n",
            "Epoch 2/3\n",
            "77/77 [==============================] - 2s 23ms/step - loss: 0.7314 - accuracy: 0.6238\n",
            "Epoch 3/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.7228 - accuracy: 0.6291\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8333 - accuracy: 0.5479\n",
            "Epoch 1/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.7437 - accuracy: 0.6180\n",
            "Epoch 2/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.7326 - accuracy: 0.6284\n",
            "Epoch 3/3\n",
            "77/77 [==============================] - 2s 23ms/step - loss: 0.7101 - accuracy: 0.6327\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8351 - accuracy: 0.5241\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 6: 0.5479000210762024\n",
            "Best solution so far: 0.57 at generation 6\n",
            "Epoch 1/3\n",
            "77/77 [==============================] - 2s 24ms/step - loss: 0.7283 - accuracy: 0.6227\n",
            "Epoch 2/3\n",
            "77/77 [==============================] - 2s 20ms/step - loss: 0.7144 - accuracy: 0.6299\n",
            "Epoch 3/3\n",
            "77/77 [==============================] - 2s 23ms/step - loss: 0.6930 - accuracy: 0.6507\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8454 - accuracy: 0.5210\n",
            "Epoch 1/3\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.5805 - accuracy: 0.7178\n",
            "Epoch 2/3\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.5561 - accuracy: 0.7314\n",
            "Epoch 3/3\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.5571 - accuracy: 0.7331\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8825 - accuracy: 0.5172\n",
            "Epoch 1/3\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 0.6734 - accuracy: 0.6659\n",
            "Epoch 2/3\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 0.6518 - accuracy: 0.6819\n",
            "Epoch 3/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.6443 - accuracy: 0.6762\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8626 - accuracy: 0.5134\n",
            "Epoch 1/3\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 0.6387 - accuracy: 0.6827\n",
            "Epoch 2/3\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6344 - accuracy: 0.6891\n",
            "Epoch 3/3\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6293 - accuracy: 0.6947\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8791 - accuracy: 0.5056\n",
            "Epoch 1/3\n",
            "61/61 [==============================] - 1s 21ms/step - loss: 0.6228 - accuracy: 0.6957\n",
            "Epoch 2/3\n",
            "61/61 [==============================] - 1s 23ms/step - loss: 0.6230 - accuracy: 0.6944\n",
            "Epoch 3/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.6207 - accuracy: 0.6874\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8656 - accuracy: 0.5141\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.7011 - accuracy: 0.6525\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.6886 - accuracy: 0.6563\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6833 - accuracy: 0.6651\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8344 - accuracy: 0.5397\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6968 - accuracy: 0.6527\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.6882 - accuracy: 0.6568\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6798 - accuracy: 0.6568\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8273 - accuracy: 0.5484\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6934 - accuracy: 0.6531\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6883 - accuracy: 0.6553\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6715 - accuracy: 0.6579\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8415 - accuracy: 0.5197\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.6923 - accuracy: 0.6578\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6765 - accuracy: 0.6593\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6795 - accuracy: 0.6590\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8571 - accuracy: 0.5140\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.6894 - accuracy: 0.6569\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6734 - accuracy: 0.6641\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6637 - accuracy: 0.6667\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8763 - accuracy: 0.4907\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 7: 0.5483999848365784\n",
            "Best solution so far: 0.57 at generation 7\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6764 - accuracy: 0.6637\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6628 - accuracy: 0.6751\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6493 - accuracy: 0.6779\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8528 - accuracy: 0.5214\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.6690 - accuracy: 0.6677\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6595 - accuracy: 0.6731\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6551 - accuracy: 0.6718\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8293 - accuracy: 0.5418\n",
            "Epoch 1/3\n",
            "77/77 [==============================] - 2s 24ms/step - loss: 0.7682 - accuracy: 0.6023\n",
            "Epoch 2/3\n",
            "77/77 [==============================] - 2s 21ms/step - loss: 0.7432 - accuracy: 0.6163\n",
            "Epoch 3/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.7229 - accuracy: 0.6245\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8443 - accuracy: 0.5297\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6658 - accuracy: 0.6708\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.6522 - accuracy: 0.6741\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.6514 - accuracy: 0.6767\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8288 - accuracy: 0.5394\n",
            "Epoch 1/3\n",
            "61/61 [==============================] - 1s 22ms/step - loss: 0.5945 - accuracy: 0.7013\n",
            "Epoch 2/3\n",
            "61/61 [==============================] - 2s 31ms/step - loss: 0.5773 - accuracy: 0.7216\n",
            "Epoch 3/3\n",
            "61/61 [==============================] - 2s 27ms/step - loss: 0.5751 - accuracy: 0.7189\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8910 - accuracy: 0.4943\n",
            "Epoch 1/3\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7249 - accuracy: 0.6312\n",
            "Epoch 2/3\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.7070 - accuracy: 0.6451\n",
            "Epoch 3/3\n",
            "86/86 [==============================] - 3s 30ms/step - loss: 0.6975 - accuracy: 0.6469\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8492 - accuracy: 0.5166\n",
            "Epoch 1/3\n",
            "92/92 [==============================] - 3s 27ms/step - loss: 0.7681 - accuracy: 0.5974\n",
            "Epoch 2/3\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 0.7601 - accuracy: 0.6016\n",
            "Epoch 3/3\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 0.7393 - accuracy: 0.6151\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8263 - accuracy: 0.5355\n",
            "Epoch 1/3\n",
            "93/93 [==============================] - 2s 26ms/step - loss: 0.7181 - accuracy: 0.6352\n",
            "Epoch 2/3\n",
            "93/93 [==============================] - 2s 24ms/step - loss: 0.7061 - accuracy: 0.6422\n",
            "Epoch 3/3\n",
            "93/93 [==============================] - 2s 22ms/step - loss: 0.6977 - accuracy: 0.6439\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8346 - accuracy: 0.5327\n",
            "Epoch 1/3\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.7274 - accuracy: 0.6276\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.7202 - accuracy: 0.6273\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 2s 21ms/step - loss: 0.7071 - accuracy: 0.6351\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8443 - accuracy: 0.5131\n",
            "Epoch 1/3\n",
            "101/101 [==============================] - 2s 22ms/step - loss: 0.7708 - accuracy: 0.5933\n",
            "Epoch 2/3\n",
            "101/101 [==============================] - 2s 23ms/step - loss: 0.7540 - accuracy: 0.6106\n",
            "Epoch 3/3\n",
            "101/101 [==============================] - 2s 24ms/step - loss: 0.7385 - accuracy: 0.6111\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.8326 - accuracy: 0.5182\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 8: 0.5418000221252441\n",
            "Best solution so far: 0.57 at generation 8\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6689 - accuracy: 0.6571\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.6530 - accuracy: 0.6658\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.6408 - accuracy: 0.6788\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8363 - accuracy: 0.5368\n",
            "Epoch 1/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.7108 - accuracy: 0.6350\n",
            "Epoch 2/3\n",
            "77/77 [==============================] - 2s 24ms/step - loss: 0.6971 - accuracy: 0.6386\n",
            "Epoch 3/3\n",
            "77/77 [==============================] - 2s 22ms/step - loss: 0.6913 - accuracy: 0.6447\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8216 - accuracy: 0.5389\n",
            "Epoch 1/3\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 0.7127 - accuracy: 0.6363\n",
            "Epoch 2/3\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 0.6967 - accuracy: 0.6411\n",
            "Epoch 3/3\n",
            "92/92 [==============================] - 2s 27ms/step - loss: 0.6975 - accuracy: 0.6376\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8303 - accuracy: 0.5221\n",
            "Epoch 1/3\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 0.6885 - accuracy: 0.6463\n",
            "Epoch 2/3\n",
            "92/92 [==============================] - 3s 30ms/step - loss: 0.6811 - accuracy: 0.6536\n",
            "Epoch 3/3\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 0.6842 - accuracy: 0.6565\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.8575 - accuracy: 0.4896\n",
            "Epoch 1/3\n",
            "78/78 [==============================] - 3s 31ms/step - loss: 0.6850 - accuracy: 0.6488\n",
            "Epoch 2/3\n",
            "78/78 [==============================] - 2s 30ms/step - loss: 0.6712 - accuracy: 0.6628\n",
            "Epoch 3/3\n",
            "78/78 [==============================] - 2s 28ms/step - loss: 0.6595 - accuracy: 0.6619\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8200 - accuracy: 0.5347\n",
            "Epoch 1/3\n",
            "100/100 [==============================] - 3s 30ms/step - loss: 0.7269 - accuracy: 0.6228\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 2s 23ms/step - loss: 0.7093 - accuracy: 0.6360\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 2s 20ms/step - loss: 0.7028 - accuracy: 0.6447\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8246 - accuracy: 0.5377\n",
            "Epoch 1/3\n",
            "113/113 [==============================] - 2s 21ms/step - loss: 0.7331 - accuracy: 0.6152\n",
            "Epoch 2/3\n",
            "113/113 [==============================] - 2s 22ms/step - loss: 0.7238 - accuracy: 0.6297\n",
            "Epoch 3/3\n",
            "113/113 [==============================] - 3s 23ms/step - loss: 0.7089 - accuracy: 0.6367\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8341 - accuracy: 0.5315\n",
            "Epoch 1/3\n",
            "107/107 [==============================] - 2s 19ms/step - loss: 0.7110 - accuracy: 0.6332\n",
            "Epoch 2/3\n",
            "107/107 [==============================] - 2s 21ms/step - loss: 0.7064 - accuracy: 0.6324\n",
            "Epoch 3/3\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.6944 - accuracy: 0.6403\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8529 - accuracy: 0.5047\n",
            "Epoch 1/3\n",
            "107/107 [==============================] - 3s 25ms/step - loss: 0.7124 - accuracy: 0.6377\n",
            "Epoch 2/3\n",
            "107/107 [==============================] - 2s 21ms/step - loss: 0.7027 - accuracy: 0.6387\n",
            "Epoch 3/3\n",
            "107/107 [==============================] - 2s 22ms/step - loss: 0.6922 - accuracy: 0.6504\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.8282 - accuracy: 0.5339\n",
            "Epoch 1/3\n",
            "114/114 [==============================] - 3s 23ms/step - loss: 0.7345 - accuracy: 0.6239\n",
            "Epoch 2/3\n",
            "114/114 [==============================] - 2s 22ms/step - loss: 0.7165 - accuracy: 0.6333\n",
            "Epoch 3/3\n",
            "114/114 [==============================] - 2s 22ms/step - loss: 0.7102 - accuracy: 0.6308\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.8512 - accuracy: 0.5065\n",
            "Elitism...\n",
            "conditions: True and 10 > 1\n",
            "Selecting...\n",
            "conditions: 5 > 9\n",
            "Crossover and mutation...\n",
            "Conditions: 5 < 10 and 5 >= 2\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Crossing over...\n",
            "Mutating...\n",
            "Best at generation 9: 0.5389000177383423\n",
            "Best solution so far: 0.57 at generation 9\n",
            "Finished in 8.857666666666667 minutes:\n",
            "\tpopulation_size: 10 \n",
            "\tselection_size: 5 \n",
            "\tmutation_rate: 0.05 \n",
            "\tcrossover_rate: 0.3 \n",
            "\tgenerations: 10 \n",
            "\telite_num: 1\n"
          ]
        }
      ],
      "source": [
        "from functools import lru_cache\n",
        "import time\n",
        "\n",
        "# cache the results of this function so that it doesn't have to be recalculated each time. Cache size is unlimited:\n",
        "# @lru_cache(maxsize=None)\n",
        "def evaluate_fitness(population):\n",
        "    fitness_scores = []\n",
        "    good_enough = []\n",
        "    good_enough_fitness = 0.00\n",
        "    \n",
        "    for individual in population:\n",
        "        corrupted_indexes = {index: index for index, value in enumerate(individual) if value == 1}\n",
        "        accuracy = trainAndEvaluateModel(x_train, y_train_onehot, x_test, y_test_onehot, model, corrupted_indexes)[1]\n",
        "\n",
        "        if accuracy > good_enough_fitness:\n",
        "            good_enough = individual\n",
        "            good_enough_fitness = round(accuracy, 2)\n",
        "            \n",
        "        if accuracy > 0.6:\n",
        "            print(\"Found a good enough solution!\")\n",
        "            break\n",
        "        \n",
        "        fitness_scores.append(accuracy)\n",
        "        \n",
        "    return fitness_scores, good_enough, good_enough_fitness\n",
        "\n",
        "def myPrunedSubsetMethod(x_train, y_train, model, population_size, selection_size, mutation_rate, crossover_rate, generations, elite_num, crossover_points, battle_participants):\n",
        "    #! global population, ELITE_NUM, SELECTION_SIZE\n",
        "    good_enough = []\n",
        "    good_enough_fitness = 0.00\n",
        "    \n",
        "    #! \n",
        "    POPULATION_SIZE = population_size\n",
        "    SELECTION_SIZE = selection_size\n",
        "    MUTATION_RATE = mutation_rate\n",
        "    CROSSOVER_RATE = crossover_rate\n",
        "    GENERATIONS = generations\n",
        "    ELITE_NUM = elite_num\n",
        "    CROSSOVER_POINTS = crossover_points\n",
        "    BATTLE_PARTICIPANTS = battle_participants\n",
        "    \n",
        "    population = create_population(POPULATION_SIZE, INPUT_SIZE, y_train, bias_strength=5800)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Run GA\n",
        "    # random.seed(SEED)\n",
        "    for generation in range(GENERATIONS):\n",
        "        \n",
        "        #' Evaluate fitness\n",
        "        # print(\"Evaluating fitness...\")\n",
        "        fitness_scores, new_best_individual, new_best_fitness = evaluate_fitness(tuple(population))\n",
        "            \n",
        "        if new_best_fitness > good_enough_fitness:\n",
        "            good_enough = new_best_individual\n",
        "            good_enough_fitness = new_best_fitness\n",
        "        \n",
        "        if good_enough_fitness > 0.6:\n",
        "            print(\"Found a good enough solution!\")\n",
        "            break\n",
        "        \n",
        "        selected_population = []\n",
        "        \n",
        "        #' Elitism:\n",
        "        print(\"Elitism...\")\n",
        "        print(f\"conditions: {elite_num > 0} and {len(population)} > {elite_num}\")\n",
        "        elite_num = min(ELITE_NUM, POPULATION_SIZE) # make sure that the number of elite individuals is not greater than the population size\n",
        "        sorted_population = sorted(zip(population, fitness_scores), key=lambda x: x[1], reverse=True)\n",
        "        if elite_num > 0 and len(population) >= elite_num:\n",
        "            selected_population += [individual[0] for individual in sorted_population[:elite_num]]\n",
        "            sorted_population = sorted_population[elite_num:]\n",
        "        \n",
        "        \n",
        "        #' Selection\n",
        "        print(\"Selecting...\")\n",
        "        print(f\"conditions: {SELECTION_SIZE} > {len(sorted_population)}\")\n",
        "        battle_participants = min(BATTLE_PARTICIPANTS, len(sorted_population)) # make sure that the number of battle participants is not greater than the population size\n",
        "        while len(selected_population) < SELECTION_SIZE:\n",
        "            to_battle = random.sample(sorted_population, battle_participants)\n",
        "            # select the fitter individual (who has the higher fitness score). x[1] is the fitness score, max()[0] to get individual array only (not fitness score):\n",
        "            selected_population.append(max(to_battle, key=lambda x: x[1])[0])\n",
        "            \n",
        "        # replace the old population with the new one for the next generation:\n",
        "        if len(selected_population) > 0:\n",
        "            population = selected_population\n",
        "            \n",
        "        #' Crossover and mutation\n",
        "        print(\"Crossover and mutation...\")\n",
        "        print(f\"Conditions: {len(population)} < {POPULATION_SIZE} and {len(population)} >= 2\")\n",
        "        while len(population) < POPULATION_SIZE and len(population) >= 2:\n",
        "            print(\"Crossing over...\")\n",
        "            parent_1, parent_2 = random.sample(population, 2)\n",
        "            child = parent_1 #if fitness_scores[population.index(parent_1)] > fitness_scores[population.index(parent_2)] else parent_2\n",
        "            # fitter = max(parent_1, parent_2, key=lambda x: fitness_scores[population.index(x)])\n",
        "            if random.random() < CROSSOVER_RATE:\n",
        "                # swap the genes from parents and append new child to selected population after mutating:\n",
        "                child = np.concatenate((parent_1[:CROSSOVER_POINTS], parent_2[CROSSOVER_POINTS:]))\n",
        "            \n",
        "            print(\"Mutating...\")\n",
        "            for i, gene in enumerate(child):\n",
        "                if random.random() < MUTATION_RATE:\n",
        "                    # flip the gene:\n",
        "                    child = np.concatenate((child[:i], [1 if gene == 0 else 0], child[i+1:]))\n",
        "\n",
        "            population.append(tuple(child))\n",
        "        \n",
        "        \n",
        "        #' Report the progress\n",
        "        sorted_population = sorted(zip(population, fitness_scores), key=lambda x: x[1], reverse=True)\n",
        "        print(f\"Best at generation {generation}: {sorted_population[0][1]}\")\n",
        "        print(f\"Best solution so far: {good_enough_fitness} at generation {generation}\")\n",
        "        with open('results.csv', 'a') as f:\n",
        "            f.write(f\"{SEED},{POPULATION_SIZE},{SELECTION_SIZE},{MUTATION_RATE},{CROSSOVER_RATE},{GENERATIONS},{ELITE_NUM},{sorted_population[0][1]},{round(time.time() - start_time, 2)}\\n\")\n",
        "        \n",
        "        \n",
        "\n",
        "    # best_solution = sorted(zip(population, fitness_scores), key=lambda x: x[1])[0][0]\n",
        "    \n",
        "    # write this result to CSV file with the hyperparameters:\n",
        "    with open('results.csv', 'a') as f:\n",
        "        f.write(f\"\\n\")\n",
        "        f.write(f\"{SEED},{POPULATION_SIZE},{SELECTION_SIZE},{MUTATION_RATE},{CROSSOVER_RATE},{GENERATIONS},{ELITE_NUM},{good_enough_fitness},{round(time.time() - start_time, 2)}\\n\")\n",
        "        \n",
        "    \n",
        "    # Return the indexes of the points to prune\n",
        "    return {index: index for index, value in enumerate(good_enough) if value == 0}\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# set up the CSV file:\n",
        "with open('results.csv', 'w') as f:\n",
        "    # reset it first:\n",
        "    f.write(\"\")\n",
        "    f.write(\"SEED,POPULATION_SIZE,SELECTION_SIZE,MUTATION_RATE,CROSSOVER_RATE,GENERATIONS,ELITE_NUM,ACCURACY,TIME_TAKEN\\n\")\n",
        "\n",
        "population_size = 10\n",
        "selection_size = ceil(0.5*population_size)\n",
        "mutation_rate = 0.05\n",
        "crossover_rate = 0.3\n",
        "generations = 10\n",
        "elite_num = 1\n",
        "crossover_points = int(0.5*INPUT_SIZE)\n",
        "battle_participants = 4\n",
        "# population = create_population(population_size, x_train.shape[0])\n",
        "# make population of 2 individuals, each mostly 1s with a random weight of 90% 1s and 10% 0s:\n",
        "# population = [tuple(np.random.choice([0, 1], size=INPUT_SIZE, p=[0.1, 0.9])) for _ in range(population_size)]\n",
        "\n",
        "start_time = time.time()\n",
        "prune_indexes = myPrunedSubsetMethod(x_train, y_train, model, population_size, selection_size, mutation_rate, crossover_rate, generations, elite_num, crossover_points, battle_participants)\n",
        "time_elapsed = round(time.time() - start_time, 2)\n",
        "unit = \"seconds\"\n",
        "if time_elapsed > 60:\n",
        "    time_elapsed = time_elapsed/60 \n",
        "    unit = \"minutes\"\n",
        "if time_elapsed > 60:\n",
        "    time_elapsed = time_elapsed/60\n",
        "    unit = \"hours\"\n",
        "print(f\"Finished in {time_elapsed} {unit}:\")\n",
        "print(f\"\\tpopulation_size: {population_size} \\n\\tselection_size: {selection_size} \\n\\tmutation_rate: {mutation_rate} \\n\\tcrossover_rate: {crossover_rate} \\n\\tgenerations: {generations} \\n\\telite_num: {elite_num}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93fb9fb6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# # global POPULATION_SIZE, SELECTION_SIZE, MUTATION_RATE, CROSSOVER_RATE, GENERATIONS, ELITE_NUM\n",
        "# DEBUG = False\n",
        "# if DEBUG:\n",
        "#     population_size_list = [1]\n",
        "#     selection_size_list = [0.5]\n",
        "#     mutation_rate_list = [0.01]\n",
        "#     crossover_rate_list = [0.3]\n",
        "#     generations_list = [1]\n",
        "#     elite_num_list = [1]\n",
        "#     crossover_points_list = [2]\n",
        "#     battle_participants_list = [2]\n",
        "    \n",
        "# else:\n",
        "#     population_size_list = sorted([50, 100, 150, 200])\n",
        "#     selection_size_list = [0.3, 0.5, 0.7, 1] # list(map(lambda x: ceil(x*POPULATION_SIZE), [0.3, 0.5, 0.7, 1]))\n",
        "#     mutation_rate_list = [0.01, 0.05, 0.1, 0.3]\n",
        "#     crossover_rate_list = [0.1, 0.3, 0.5]\n",
        "#     generations_list = [10, 30, 100]\n",
        "#     elite_num_list = [2]\n",
        "#     crossover_points_list = [2, 4, 8, 10]\n",
        "#     battle_participants_list = [2, 4, 8, 10]\n",
        "\n",
        "# population = create_population(POPULATION_SIZE, INPUT_SIZE)\n",
        "\n",
        "# for population_size in population_size_list:\n",
        "#     # Clear the cache with each new population size:\n",
        "#     evaluate_fitness.cache_clear()\n",
        "    \n",
        "#     for selection_size in selection_size_list:\n",
        "#         selection_size = ceil(selection_size*population_size)\n",
        "#         for mutation_rate in mutation_rate_list:\n",
        "#             for crossover_rate in crossover_rate_list:\n",
        "#                 if crossover_rate > mutation_rate:\n",
        "#                     for generations in generations_list:\n",
        "#                         for elite_num in elite_num_list:\n",
        "#                             for crossover_points in crossover_points_list:\n",
        "#                                 for battle_participants in battle_participants_list:\n",
        "#                                     start_time = time.time()\n",
        "#                                     myPrunedSubsetMethod(x_train, y_train, model, population_size, selection_size, mutation_rate, crossover_rate, generations, elite_num, crossover_points, battle_participants, population)\n",
        "#                                     time_elapsed = round(time.time() - start_time, 2)\n",
        "#                                     unit = \"seconds\"\n",
        "#                                     if time_elapsed > 60:\n",
        "#                                         time_elapsed = time_elapsed/60\n",
        "#                                         unit = \"minutes\"\n",
        "#                                     if time_elapsed > 60:\n",
        "#                                         time_elapsed = time_elapsed/60\n",
        "#                                         unit = \"hours\"\n",
        "#                                     print(f\"Finished in {time_elapsed} {unit}:\")\n",
        "#                                     print(f\"\\tpopulation_size: {population_size} \\n\\tselection_size: {selection_size} \\n\\tmutation_rate: {mutation_rate} \\n\\tcrossover_rate: {crossover_rate} \\n\\tgenerations: {generations} \\n\\telite_num: {elite_num}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eae6e36",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# trainAndEvaluateModel(x_train, y_train_onehot, x_test, y_test_onehot, model, pruned_indexes)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
